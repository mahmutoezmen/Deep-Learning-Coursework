{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RNEnVNj8gzH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ac7534c-9f31-4fd3-8cfb-2db58c9c8c30"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import matplotlib.colors as clr\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.core import Dense, Activation, Dropout"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5qq5oCgkKDL"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVGFunm48wYD",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "f4a3322c-f806-4c78-c0f0-b5875a00e9b3"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9856fb65-2760-41c5-bd85-ce0a2944a507\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9856fb65-2760-41c5-bd85-ce0a2944a507\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving rnn-challenge-data.npz to rnn-challenge-data (2).npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGAKaGiQ8tii",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "003896ed-50a1-40b1-f09b-0dff12123cf4"
      },
      "source": [
        "with np.load('rnn-challenge-data.npz') as fh:\n",
        "    x_train = fh['data_x']\n",
        "    y_train = fh['data_y']\n",
        "    x_val = fh['val_x']\n",
        "    y_val = fh['val_y']\n",
        "    x_test = fh['test_x']\n",
        "\n",
        "\n",
        "print(x_train.shape, x_train.dtype)\n",
        "print(y_train.shape, y_train.dtype)\n",
        "\n",
        "print(x_val.shape, x_val.dtype)\n",
        "print(y_val.shape, y_val.dtype)\n",
        "\n",
        "print(x_test.shape, x_test.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(400,) <U400\n",
            "(400,) int64\n",
            "(100,) <U1200\n",
            "(100,) int64\n",
            "(250,) <U2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daANzmn0kMxw"
      },
      "source": [
        "# Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWS8K_WzMUeA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5a5dc4a9-f335-4200-cd74-c13bbdcace58"
      },
      "source": [
        "letter_dict = list(dict.fromkeys(x_train[0]))\n",
        "print(letter_dict)\n",
        "\n",
        "label_dict = list(dict.fromkeys(y_train))\n",
        "print(label_dict)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['C', 'T', 'A', 'G']\n",
            "[2, 0, 4, 3, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDjDVo4lOdRy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fc691362-ed4c-4dc0-9cf8-4de71cc53f12"
      },
      "source": [
        "# Creating a dictionary that maps integers to the characters\n",
        "int2char = dict(enumerate(x_train[0]))\n",
        "# Creating another dictionary that maps characters to integers\n",
        "char2int = {char: ind for ind, char in int2char.items()}\n",
        "print(char2int)\n",
        "\n",
        "for key in char2int.keys():\n",
        "  char2int[key] = char2int[key] - 396\n",
        "print(char2int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': 396, 'T': 397, 'A': 398, 'G': 399}\n",
            "{'C': 0, 'T': 1, 'A': 2, 'G': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET4ebQ-qMuVL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67e6edef-2d24-4073-d25e-d5f1ee488717"
      },
      "source": [
        "maxlen = len(max(x_train, key=len))\n",
        "print(\"The longest string has {} characters\".format(maxlen))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The longest string has 400 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKdXYhJoPUb4"
      },
      "source": [
        "Now we can convert our input sequences to sequences of integers instead of characters by mapping them using the dictionaries we created above. This will allow us to one-hot-encode our input sequence subsequently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YLyJr4aPTm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "0cc4ff65-c0a4-44a5-8b30-285ede6b3c29"
      },
      "source": [
        "x_train_integer = []\n",
        "x_val_integer = []\n",
        "x_test_integer= []\n",
        "\n",
        "for i in range(len(x_train)):\n",
        "    # Remove last character for input sequence\n",
        "    x_train_integer.append(x_train[i])\n",
        "for i in range(len(x_train)):\n",
        "    x_train_integer[i] = [char2int[character] for character in x_train_integer[i]]\n",
        "\n",
        "\n",
        "for i in range(len(x_val)):\n",
        "    # Remove last character for input sequence\n",
        "    x_val_integer.append(x_val[i])\n",
        "for i in range(len(x_val)):\n",
        "    x_val_integer[i] = [char2int[character] for character in x_val_integer[i]]\n",
        "\n",
        "\n",
        "for i in range(len(x_test)):\n",
        "    # Remove last character for input sequence\n",
        "    x_test_integer.append(x_test[i])\n",
        "for i in range(len(x_test)):\n",
        "    x_test_integer[i] = [char2int[character] for character in x_test_integer[i]]\n",
        "\n",
        "print(x_train[0])\n",
        "print(x_train_integer[0])\n",
        "print('---------------------------------')\n",
        "print(x_train[0])\n",
        "print(x_train_integer[0])\n",
        "print('---------------------------------')\n",
        "print(x_train[0])\n",
        "print(x_train_integer[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CTAGCTGAGCTACTGAGCTACAGTTGACTGACCAGTCAGTGCTAGCTACTGACAGTCTGACAGTTGACCTGACTGATGACCAGTCTAGCAGTGCTACTAGCTAGGCTACAGTCAGTTGACCAGTCTGACAGTCAGTCTGACTGACAGTCAGTCTAGGCTATGACCTGACTGATGACCTGACTGACTGACAGTCTGACTGATGACGCTATGACCTGACTAGCTAGCAGTTGACTGACCTGACAGTGCTACTAGCAGTTGACCAGTGCTACAGTCTGATGACTGACCTGACAGTCTAGGCTACAGTTGACCTGACAGTCAGTGCTACTGACAGTCTAGTGACCAGTCAGTCAGTTGACCTGACTAGCAGTTGACGCTATGACCAGTCTGACAGTGCTACTAG\n",
            "[0, 1, 2, 3, 0, 1, 3, 2, 3, 0, 1, 2, 0, 1, 3, 2, 3, 0, 1, 2, 0, 2, 3, 1, 1, 3, 2, 0, 1, 3, 2, 0, 0, 2, 3, 1, 0, 2, 3, 1, 3, 0, 1, 2, 3, 0, 1, 2, 0, 1, 3, 2, 0, 2, 3, 1, 0, 1, 3, 2, 0, 2, 3, 1, 1, 3, 2, 0, 0, 1, 3, 2, 0, 1, 3, 2, 1, 3, 2, 0, 0, 2, 3, 1, 0, 1, 2, 3, 0, 2, 3, 1, 3, 0, 1, 2, 0, 1, 2, 3, 0, 1, 2, 3, 3, 0, 1, 2, 0, 2, 3, 1, 0, 2, 3, 1, 1, 3, 2, 0, 0, 2, 3, 1, 0, 1, 3, 2, 0, 2, 3, 1, 0, 2, 3, 1, 0, 1, 3, 2, 0, 1, 3, 2, 0, 2, 3, 1, 0, 2, 3, 1, 0, 1, 2, 3, 3, 0, 1, 2, 1, 3, 2, 0, 0, 1, 3, 2, 0, 1, 3, 2, 1, 3, 2, 0, 0, 1, 3, 2, 0, 1, 3, 2, 0, 1, 3, 2, 0, 2, 3, 1, 0, 1, 3, 2, 0, 1, 3, 2, 1, 3, 2, 0, 3, 0, 1, 2, 1, 3, 2, 0, 0, 1, 3, 2, 0, 1, 2, 3, 0, 1, 2, 3, 0, 2, 3, 1, 1, 3, 2, 0, 1, 3, 2, 0, 0, 1, 3, 2, 0, 2, 3, 1, 3, 0, 1, 2, 0, 1, 2, 3, 0, 2, 3, 1, 1, 3, 2, 0, 0, 2, 3, 1, 3, 0, 1, 2, 0, 2, 3, 1, 0, 1, 3, 2, 1, 3, 2, 0, 1, 3, 2, 0, 0, 1, 3, 2, 0, 2, 3, 1, 0, 1, 2, 3, 3, 0, 1, 2, 0, 2, 3, 1, 1, 3, 2, 0, 0, 1, 3, 2, 0, 2, 3, 1, 0, 2, 3, 1, 3, 0, 1, 2, 0, 1, 3, 2, 0, 2, 3, 1, 0, 1, 2, 3, 1, 3, 2, 0, 0, 2, 3, 1, 0, 2, 3, 1, 0, 2, 3, 1, 1, 3, 2, 0, 0, 1, 3, 2, 0, 1, 2, 3, 0, 2, 3, 1, 1, 3, 2, 0, 3, 0, 1, 2, 1, 3, 2, 0, 0, 2, 3, 1, 0, 1, 3, 2, 0, 2, 3, 1, 3, 0, 1, 2, 0, 1, 2, 3]\n",
            "---------------------------------\n",
            "CTAGCTGAGCTACTGAGCTACAGTTGACTGACCAGTCAGTGCTAGCTACTGACAGTCTGACAGTTGACCTGACTGATGACCAGTCTAGCAGTGCTACTAGCTAGGCTACAGTCAGTTGACCAGTCTGACAGTCAGTCTGACTGACAGTCAGTCTAGGCTATGACCTGACTGATGACCTGACTGACTGACAGTCTGACTGATGACGCTATGACCTGACTAGCTAGCAGTTGACTGACCTGACAGTGCTACTAGCAGTTGACCAGTGCTACAGTCTGATGACTGACCTGACAGTCTAGGCTACAGTTGACCTGACAGTCAGTGCTACTGACAGTCTAGTGACCAGTCAGTCAGTTGACCTGACTAGCAGTTGACGCTATGACCAGTCTGACAGTGCTACTAG\n",
            "[0, 1, 2, 3, 0, 1, 3, 2, 3, 0, 1, 2, 0, 1, 3, 2, 3, 0, 1, 2, 0, 2, 3, 1, 1, 3, 2, 0, 1, 3, 2, 0, 0, 2, 3, 1, 0, 2, 3, 1, 3, 0, 1, 2, 3, 0, 1, 2, 0, 1, 3, 2, 0, 2, 3, 1, 0, 1, 3, 2, 0, 2, 3, 1, 1, 3, 2, 0, 0, 1, 3, 2, 0, 1, 3, 2, 1, 3, 2, 0, 0, 2, 3, 1, 0, 1, 2, 3, 0, 2, 3, 1, 3, 0, 1, 2, 0, 1, 2, 3, 0, 1, 2, 3, 3, 0, 1, 2, 0, 2, 3, 1, 0, 2, 3, 1, 1, 3, 2, 0, 0, 2, 3, 1, 0, 1, 3, 2, 0, 2, 3, 1, 0, 2, 3, 1, 0, 1, 3, 2, 0, 1, 3, 2, 0, 2, 3, 1, 0, 2, 3, 1, 0, 1, 2, 3, 3, 0, 1, 2, 1, 3, 2, 0, 0, 1, 3, 2, 0, 1, 3, 2, 1, 3, 2, 0, 0, 1, 3, 2, 0, 1, 3, 2, 0, 1, 3, 2, 0, 2, 3, 1, 0, 1, 3, 2, 0, 1, 3, 2, 1, 3, 2, 0, 3, 0, 1, 2, 1, 3, 2, 0, 0, 1, 3, 2, 0, 1, 2, 3, 0, 1, 2, 3, 0, 2, 3, 1, 1, 3, 2, 0, 1, 3, 2, 0, 0, 1, 3, 2, 0, 2, 3, 1, 3, 0, 1, 2, 0, 1, 2, 3, 0, 2, 3, 1, 1, 3, 2, 0, 0, 2, 3, 1, 3, 0, 1, 2, 0, 2, 3, 1, 0, 1, 3, 2, 1, 3, 2, 0, 1, 3, 2, 0, 0, 1, 3, 2, 0, 2, 3, 1, 0, 1, 2, 3, 3, 0, 1, 2, 0, 2, 3, 1, 1, 3, 2, 0, 0, 1, 3, 2, 0, 2, 3, 1, 0, 2, 3, 1, 3, 0, 1, 2, 0, 1, 3, 2, 0, 2, 3, 1, 0, 1, 2, 3, 1, 3, 2, 0, 0, 2, 3, 1, 0, 2, 3, 1, 0, 2, 3, 1, 1, 3, 2, 0, 0, 1, 3, 2, 0, 1, 2, 3, 0, 2, 3, 1, 1, 3, 2, 0, 3, 0, 1, 2, 1, 3, 2, 0, 0, 2, 3, 1, 0, 1, 3, 2, 0, 2, 3, 1, 3, 0, 1, 2, 0, 1, 2, 3]\n",
            "---------------------------------\n",
            "CTAGCTGAGCTACTGAGCTACAGTTGACTGACCAGTCAGTGCTAGCTACTGACAGTCTGACAGTTGACCTGACTGATGACCAGTCTAGCAGTGCTACTAGCTAGGCTACAGTCAGTTGACCAGTCTGACAGTCAGTCTGACTGACAGTCAGTCTAGGCTATGACCTGACTGATGACCTGACTGACTGACAGTCTGACTGATGACGCTATGACCTGACTAGCTAGCAGTTGACTGACCTGACAGTGCTACTAGCAGTTGACCAGTGCTACAGTCTGATGACTGACCTGACAGTCTAGGCTACAGTTGACCTGACAGTCAGTGCTACTGACAGTCTAGTGACCAGTCAGTCAGTTGACCTGACTAGCAGTTGACGCTATGACCAGTCTGACAGTGCTACTAG\n",
            "[0, 1, 2, 3, 0, 1, 3, 2, 3, 0, 1, 2, 0, 1, 3, 2, 3, 0, 1, 2, 0, 2, 3, 1, 1, 3, 2, 0, 1, 3, 2, 0, 0, 2, 3, 1, 0, 2, 3, 1, 3, 0, 1, 2, 3, 0, 1, 2, 0, 1, 3, 2, 0, 2, 3, 1, 0, 1, 3, 2, 0, 2, 3, 1, 1, 3, 2, 0, 0, 1, 3, 2, 0, 1, 3, 2, 1, 3, 2, 0, 0, 2, 3, 1, 0, 1, 2, 3, 0, 2, 3, 1, 3, 0, 1, 2, 0, 1, 2, 3, 0, 1, 2, 3, 3, 0, 1, 2, 0, 2, 3, 1, 0, 2, 3, 1, 1, 3, 2, 0, 0, 2, 3, 1, 0, 1, 3, 2, 0, 2, 3, 1, 0, 2, 3, 1, 0, 1, 3, 2, 0, 1, 3, 2, 0, 2, 3, 1, 0, 2, 3, 1, 0, 1, 2, 3, 3, 0, 1, 2, 1, 3, 2, 0, 0, 1, 3, 2, 0, 1, 3, 2, 1, 3, 2, 0, 0, 1, 3, 2, 0, 1, 3, 2, 0, 1, 3, 2, 0, 2, 3, 1, 0, 1, 3, 2, 0, 1, 3, 2, 1, 3, 2, 0, 3, 0, 1, 2, 1, 3, 2, 0, 0, 1, 3, 2, 0, 1, 2, 3, 0, 1, 2, 3, 0, 2, 3, 1, 1, 3, 2, 0, 1, 3, 2, 0, 0, 1, 3, 2, 0, 2, 3, 1, 3, 0, 1, 2, 0, 1, 2, 3, 0, 2, 3, 1, 1, 3, 2, 0, 0, 2, 3, 1, 3, 0, 1, 2, 0, 2, 3, 1, 0, 1, 3, 2, 1, 3, 2, 0, 1, 3, 2, 0, 0, 1, 3, 2, 0, 2, 3, 1, 0, 1, 2, 3, 3, 0, 1, 2, 0, 2, 3, 1, 1, 3, 2, 0, 0, 1, 3, 2, 0, 2, 3, 1, 0, 2, 3, 1, 3, 0, 1, 2, 0, 1, 3, 2, 0, 2, 3, 1, 0, 1, 2, 3, 1, 3, 2, 0, 0, 2, 3, 1, 0, 2, 3, 1, 0, 2, 3, 1, 1, 3, 2, 0, 0, 1, 3, 2, 0, 1, 2, 3, 0, 2, 3, 1, 1, 3, 2, 0, 3, 0, 1, 2, 1, 3, 2, 0, 0, 2, 3, 1, 0, 1, 3, 2, 0, 2, 3, 1, 3, 0, 1, 2, 0, 1, 2, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVRpbsTML9Vj"
      },
      "source": [
        "Before encoding our input sequence into one-hot vectors, we'll define 3 key variables:\n",
        "\n",
        "-dict_size: The number of unique characters that we have in our text\n",
        "This will determine the one-hot vector size as each character will have an assigned index in that vector\n",
        "\n",
        "-seq_len: The length of the sequences that we're feeding into the model\n",
        "As we standardised the length of all our sentences to be equal to the longest sentences, this value will be the max length - 1 as we removed the last character input as well\n",
        "\n",
        "-batch_size: The number of sentences that we defined and are going to feed into the model as a batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgLcTk_HLuuv"
      },
      "source": [
        "dict_size = len(letter_dict)\n",
        "seq_len = maxlen\n",
        "\n",
        "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
        "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
        "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
        "\n",
        "    print(features.shape)\n",
        "    print(features.dtype)\n",
        "    \n",
        "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
        "    for i in range(batch_size):\n",
        "        for u in range(seq_len):\n",
        "            features[i][u][sequence[i][u]] = 1\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OugqxzGNhwE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d46bb064-8a0b-4f70-8359-26431d892d39"
      },
      "source": [
        "x_train_integer = one_hot_encode(x_train_integer, dict_size, seq_len, len(x_train))\n",
        "x_val_integer = one_hot_encode(x_val_integer, dict_size, seq_len, len(x_val))\n",
        "x_test_integer = one_hot_encode(x_test_integer, dict_size, seq_len, len(x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(400, 400, 4)\n",
            "float32\n",
            "(100, 400, 4)\n",
            "float32\n",
            "(250, 400, 4)\n",
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QW0FA8cuVaa"
      },
      "source": [
        "labels = 5\n",
        "def y_hot_encode(y):\n",
        "  y_integer = []\n",
        "  for i in y:\n",
        "    l = [0]* labels\n",
        "    l[i] = 1\n",
        "    y_integer.append(l)\n",
        "  return y_integer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYGAxZZbu-gd"
      },
      "source": [
        "y_train_integer = y_hot_encode(y_train)\n",
        "y_val_integer = y_hot_encode(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBM9Lsd-kXL2"
      },
      "source": [
        "# RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv4qeSIsrtr1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9f0bd85b-5fc1-46fc-dfea-55efde3b28bc"
      },
      "source": [
        "#Hyper parameters\n",
        "word_vec_length = 400 # Length of the input vector\n",
        "char_vec_length = 4 # Length of the character vector\n",
        "output_labels = 5 # Number of output labels\n",
        "\n",
        "print(f\"The input vector will have the shape {word_vec_length}x{char_vec_length}.\")\n",
        "# Out: The input vector will have the shape 23x30.\n",
        "hidden_nodes = int(2/3 * (word_vec_length * char_vec_length))\n",
        "print(f\"The number of hidden nodes is {hidden_nodes}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The input vector will have the shape 400x4.\n",
            "The number of hidden nodes is 1066.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfnIKoYd9jnq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "069ee744-e7d6-4053-d4aa-d9a037533984"
      },
      "source": [
        "# Build the model\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_nodes, return_sequences=False, input_shape=(word_vec_length, char_vec_length)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=output_labels))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "batch_size=100\n",
        "model.fit(x_train_integer, y_train, batch_size=batch_size, epochs=40, validation_data=(x_val_integer, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "Train on 400 samples, validate on 100 samples\n",
            "Epoch 1/40\n",
            "400/400 [==============================] - 8s 19ms/step - loss: 1.6207 - acc: 0.1600 - val_loss: 1.6063 - val_acc: 0.2700\n",
            "Epoch 2/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.6054 - acc: 0.2350 - val_loss: 1.6039 - val_acc: 0.2000\n",
            "Epoch 3/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.5990 - acc: 0.2075 - val_loss: 1.5997 - val_acc: 0.3100\n",
            "Epoch 4/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.5955 - acc: 0.2525 - val_loss: 1.5964 - val_acc: 0.2300\n",
            "Epoch 5/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.5866 - acc: 0.2800 - val_loss: 1.5923 - val_acc: 0.2100\n",
            "Epoch 6/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.5762 - acc: 0.2950 - val_loss: 1.5891 - val_acc: 0.2000\n",
            "Epoch 7/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.5692 - acc: 0.2850 - val_loss: 1.5855 - val_acc: 0.1900\n",
            "Epoch 8/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.5503 - acc: 0.3200 - val_loss: 1.6697 - val_acc: 0.3100\n",
            "Epoch 9/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.5651 - acc: 0.3175 - val_loss: 1.5826 - val_acc: 0.2700\n",
            "Epoch 10/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.5359 - acc: 0.3125 - val_loss: 1.5852 - val_acc: 0.2400\n",
            "Epoch 11/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.5278 - acc: 0.3150 - val_loss: 1.5878 - val_acc: 0.2400\n",
            "Epoch 12/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.5121 - acc: 0.3225 - val_loss: 1.6058 - val_acc: 0.2300\n",
            "Epoch 13/40\n",
            "400/400 [==============================] - 7s 17ms/step - loss: 1.5007 - acc: 0.3100 - val_loss: 1.6266 - val_acc: 0.2100\n",
            "Epoch 14/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4884 - acc: 0.3400 - val_loss: 1.5775 - val_acc: 0.2300\n",
            "Epoch 15/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4757 - acc: 0.3475 - val_loss: 1.5709 - val_acc: 0.2700\n",
            "Epoch 16/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4431 - acc: 0.3750 - val_loss: 1.5361 - val_acc: 0.2900\n",
            "Epoch 17/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4607 - acc: 0.3625 - val_loss: 1.5155 - val_acc: 0.3600\n",
            "Epoch 18/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4529 - acc: 0.3500 - val_loss: 1.5218 - val_acc: 0.3300\n",
            "Epoch 19/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4393 - acc: 0.3750 - val_loss: 1.5025 - val_acc: 0.3900\n",
            "Epoch 20/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4563 - acc: 0.3250 - val_loss: 1.5015 - val_acc: 0.3200\n",
            "Epoch 21/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4523 - acc: 0.3175 - val_loss: 1.4918 - val_acc: 0.3300\n",
            "Epoch 22/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4380 - acc: 0.3275 - val_loss: 1.4735 - val_acc: 0.3400\n",
            "Epoch 23/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4163 - acc: 0.3250 - val_loss: 1.4390 - val_acc: 0.3700\n",
            "Epoch 24/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.3658 - acc: 0.3550 - val_loss: 1.2949 - val_acc: 0.3900\n",
            "Epoch 25/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.7565 - acc: 0.3175 - val_loss: 1.7541 - val_acc: 0.2100\n",
            "Epoch 26/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.9736 - acc: 0.2200 - val_loss: 1.8296 - val_acc: 0.2500\n",
            "Epoch 27/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.6270 - acc: 0.2375 - val_loss: 1.6305 - val_acc: 0.1900\n",
            "Epoch 28/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.5257 - acc: 0.2650 - val_loss: 1.5993 - val_acc: 0.2200\n",
            "Epoch 29/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.5099 - acc: 0.2725 - val_loss: 1.5886 - val_acc: 0.2000\n",
            "Epoch 30/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4966 - acc: 0.2850 - val_loss: 1.5809 - val_acc: 0.2300\n",
            "Epoch 31/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4951 - acc: 0.3025 - val_loss: 1.5721 - val_acc: 0.2700\n",
            "Epoch 32/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4868 - acc: 0.3250 - val_loss: 1.5629 - val_acc: 0.2600\n",
            "Epoch 33/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4805 - acc: 0.3325 - val_loss: 1.5527 - val_acc: 0.2400\n",
            "Epoch 34/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4718 - acc: 0.3450 - val_loss: 1.5430 - val_acc: 0.2500\n",
            "Epoch 35/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4641 - acc: 0.3175 - val_loss: 1.5335 - val_acc: 0.2500\n",
            "Epoch 36/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4585 - acc: 0.3450 - val_loss: 1.5237 - val_acc: 0.2900\n",
            "Epoch 37/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4484 - acc: 0.3725 - val_loss: 1.5143 - val_acc: 0.3000\n",
            "Epoch 38/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4386 - acc: 0.3675 - val_loss: 1.5032 - val_acc: 0.3100\n",
            "Epoch 39/40\n",
            "400/400 [==============================] - 7s 18ms/step - loss: 1.4287 - acc: 0.3750 - val_loss: 1.4883 - val_acc: 0.3500\n",
            "Epoch 40/40\n",
            "100/400 [======>.......................] - ETA: 4s - loss: 1.3858 - acc: 0.4400"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JvZYMk8tXHH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5fa0e91c-124d-4a7d-bb9c-75f9fe1b7f9e"
      },
      "source": [
        "loss, accuracy = model.evaluate(x_val_integer, y_val)\n",
        "print(loss, accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 1s 11ms/step\n",
            "3.396847128868103 0.28999999165534973\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}